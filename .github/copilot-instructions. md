# GitHub Copilot Custom Instructions for Databricks Data Engineer Professional Study Guide

## Purpose
This repository is dedicated to building a comprehensive study guide for the **Databricks Certified Data Engineer Professional** certification. The goal is to create structured, accurate, and exam-relevant content that helps learners prepare effectively.

## Copilot Behavior Guidelines

### âœ… Content Focus
Copilot should prioritize generating content related to:
- Apache Spark (core concepts, optimization, performance tuning)
- Delta Lake (architecture, features, use cases)
- Databricks SQL and Lakehouse architecture
- Data ingestion, transformation, and orchestration
- Streaming data pipelines (Structured Streaming, Auto Loader)
- Data governance, security, and monitoring in Databricks
- MLflow and machine learning pipeline integration
- Best practices for scalable and reliable data engineering

### ðŸ“š Source Material

Copilot should use the following as reference anchors:
- The official Databricks exam guide (found in db_studyguide.md)
- Sample questions provided by Databricks (found in db_studyguide.md)
- Databricks documentation and blog posts
- Apache Spark documentation

### ðŸ§  Output Style
Copilot should generate:
- Concise explanations of key concepts
- Annotated code examples in PySpark and SQL
- Practice questions with answers and explanations
- Summary tables and diagrams (in Markdown or Mermaid)
- Tips and tricks for exam preparation

### ðŸš« Avoid
- Overly verbose or generic content
- Unverified or speculative information
- Content unrelated to Databricks or Spark ecosystem

## File Structure Suggestions
Copilot can help maintain the following structure:

/databricks-engineer-professional-study-guide/
â”‚
â”œâ”€â”€ README.md                        # Overview of the study guide, usage instructions, and resources
â”œâ”€â”€ custom-instructions.md          # GitHub Copilot guidance file
â”‚
â”œâ”€â”€ exam-guide/                     # Official exam guide and reference materials
â”‚   â”œâ”€â”€ databricks_exam_outline.md
â”‚   â””â”€â”€ sample_questions.md
â”‚
â”œâ”€â”€ modules/                        # Core study modules aligned with exam domains
â”‚   â”œâ”€â”€ 01_spark_core.md            # Spark architecture, transformations, actions, caching
â”‚   â”œâ”€â”€ 02_delta_lake.md            # Delta Lake features, schema enforcement, time travel
â”‚   â”œâ”€â”€ 03_streaming.md             # Structured Streaming, Auto Loader, watermarking
â”‚   â”œâ”€â”€ 04_sql_lakehouse.md         # Databricks SQL, Lakehouse concepts, query optimization
â”‚   â”œâ”€â”€ 05_mlflow.md                # MLflow tracking, models, integration with pipelines
â”‚   â”œâ”€â”€ 06_governance_monitoring.md# Unity Catalog, data lineage, audit logging, alerting
â”‚   â””â”€â”€ 07_pipeline_orchestration.md# Workflows, task dependencies, error handling
â”‚
â”œâ”€â”€ practice-questions/             # Practice sets with answers and explanations
â”‚   â”œâ”€â”€ set_01_foundations.md
â”‚   â”œâ”€â”€ set_02_intermediate.md
â”‚   â””â”€â”€ set_03_advanced.md
â”‚
â”œâ”€â”€ cheatsheets/                    # Quick reference guides
â”‚   â”œâ”€â”€ spark_cheatsheet.md
â”‚   â”œâ”€â”€ delta_lake_cheatsheet.md
â”‚   â””â”€â”€ streaming_cheatsheet.md
â”‚
â”œâ”€â”€ diagrams/                       # Mermaid or image-based diagrams
â”‚   â”œâ”€â”€ lakehouse_architecture.mmd
â”‚   â”œâ”€â”€ streaming_pipeline_flow.mmd
â”‚   â””â”€â”€ governance_stack.mmd
â”‚
â””â”€â”€ resources/                      # External links, documentation, and blog references
    â”œâ”€â”€ official_docs.md
    â””â”€â”€ recommended_reading.md

## Tone & Audience
The guide should be written in a professional but approachable tone, suitable for experienced data engineers preparing for certification.

## Additional Notes
- Use bullet points and headings for readability.
- Include links to official documentation where relevant.
- When generating code, include comments explaining each step.
